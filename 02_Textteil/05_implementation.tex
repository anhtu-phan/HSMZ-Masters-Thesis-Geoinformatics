\chapter{Implementation}

\section{Infrastructure setup}

Initially, the supporting server infrastructure was deployed to allow development on a working WebRTC infrastructure. The basis was a clean, freshly bootstrapped Kubernetes installation running on a single server with 16 CPU-cores (with multithreading), 64GB RAM and a 512GB SSD drive, located at Mainz University and connected to the internet via a one gigabit network connection. LiveKit and its Redis database are installed via the application deployment manager Helm, using an official installation from its maintainers. To simplify the deployment, LiveKit is placed behind a reverse proxy (Traefik) to manage SSL termination via the LetsEncrypt service, as well as routing to the actual service running inside the cluster. This simplified setup results in LiveKit being accessible on a single TCP port instead of a range of UDP ports, as WebRTC would usually be deployed. The detailed Kubernetes setup instructions are documented in the according folder in the Git repository \footnote{Kubernetes setup instructions: \href{https://github.com/dasantonym/sensorama/tree/master/kubernetes}{https://github.com/dasantonym/sensorama/tree/master/kubernetes}}.

\section{Development setup}

The development takes place in a desktop environment, using the suite of tools developed by JetBrains (WebStorm, PyCharm and CLion), as these are free for educational use and provide a complete environment for development including debugging, smart code-completion, versioning, containerisation and deployment. A local Docker Desktop installation provides the possibility to run services and databases locally to support development before publishing to the production environment. Versioning is done via Git on the GitLab platform provided by Mainz University for the Rhineland-Palatinate \footnote{https://gitlab.rlp.net}{https://gitlab.rlp.net}.

\section{Application}

The application is made up of the following components.

(ILLUSTRATION)


\subsection{API server}

The \ac{API} server implements the core services for Users, Spaces and Tokens as defined in \autoref{section:dataModeling}. These services are autogenerated using the Feathers \ac{CLI} utility and are used largely unmodified, except for several property changes on the models for Users and Spaces (persisted in MongoDB), as well as a custom service class being used for the Tokens, as these are not persisted in the database, but generated on the fly by the LiveKit server \ac{SDK}. All other boilerplate code for the \ac{API}, including the authentication mechanism, as well as the REST and WebSockets transport integrations, is also autogenerated using the \ac{CLI}. An additional custom LivekitEvent service is added to the API, which allows to receive webhook requests via HTTP from the LiveKit server with updates on connecting and disconnecting users. These events are not persisted, but relayed to the real-time channels that the users are connected to. The channels feature provided by Feathers is used to subscribe connecting users to updates on the services for Spaces and LivekitEvents.

\subsection{LiveKit WebRTC server}

The LiveKit server is deployed with slight deviation from the default config. It uses TCP as a transport protocol to allow easier integration with SLL termination by the Traefik reverse-proxy. Otherwise, the configuration just defines the endpoints for sending webhook requests and custom credentials for making requests to it via the server-side \ac{SDK} and generating valid access tokens for users to connect to rooms.

\subsection{User interface}

The user interface is structured as follows:

(ILLUSTRATION)

\subsection{Data producers}

There are three different data producer projects that connect to the user interface in the browser.

The main producer is a Python project providing an interface to a Blazepose implementation on the Oak-D \ac{3D} camera, as well as reading depth images as point clouds from the camera and an interface to load and playback motion capture data in the \ac{BVH} file format.

Then there is a custom built head tracking device that is implemented as an Arduino project and that connects using the BluetoothLE standard via \ac{GATT}.

The third producer is a native integration of the RemoteCaptury library, that allows streaming pose data live from the motion capture system via WebSockets to the browser.


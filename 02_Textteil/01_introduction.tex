\chapter{Introduction}
\label{chapter:introduction}

\section{Background}

Remote collaboration has become increasingly prevalent in various professional environments, both through broader digitalisation efforts, but especially accelerated during the Covid pandemic.
As a result, teleconferencing and telepresence platforms that were initally used mostly in international business relations have become more pervasive in many work environments.
These technologies allow people to work together remotely in real-time, usually focusing on streaming video and audio, document sharing or collaborative whiteboarding.
While this covers most use cases in desk-based workplaces, it lacks immersive qualities required for practices such as contemporary dance, where people relate to physical presence and shared space.
This became apparent in March 2020, when dancers could no longer rehearse and work together due to the lockdown.
Despite this, there were attempts at using videoconferencing to stream and record collaborative rehearsals or dance classes.
Still, these were confined to a screen-centric interface and limited to audio and video.

While commercial conferencing tools dominate in popularity among conferencing applications \parencite{mostPopularConferencingPlatforms}, there are a number of free and open-source alternatives.
However, these all focus on the most basic form of screen-based conferencing mentioned above.
There are various domain-specific solutions for specialised applications, mainly in telemedicine, industry and the military, that support more immersive remote collaboration, these are task-specific and difficult to afford for experimental artistic project setups.

Support for web standards is driven by key industry players \parencite{pushingInteroperabilityForward}, and with it the availability of a wide range of basic functionality, as well as access to display and sensor technology for deploying applications on desktop and mobile devices.
There is an increased potential for smaller and more task-specific applications to be built and deployed with relative ease.
This opens up new possibilities for niche cases of remote collaboration, such as dance practice, where collaborative agency could be extended from a composite of video streams to the creation of shared virtual environments that facilitate a more personal form of mediating a sense of shared presence.

The standard for \ac{RTC} in Browsers or \ac{WebRTC} \parencite{webRtcSpec} was first proposed by Google in 2011 and became an official \ac{W3C} standard in 2021 \parencite{webRtcOfficialWebStandard}.
It has become the basis for numerous applications, such as some of the conferencing tools mentioned above, media streaming servers such as Wowza or Ant, or real-time frameworks and servers such as Mediasoup, Janus or LiveKit.
In its most basic form, \ac{WebRTC} establishes peer-to-peer connections between different devices, allowing low-latency exchange of media streams and arbitrary messages over data channels.

\section{Proposal}

The proposed study will examine the feasibility of creating a customised telepresence experience that explicitly covers a specific task not provided by common platforms or products.
A potential target audience for such an application would be very small and hardly warrants a commercial strategy of external product development, marketing and support.
Extensive software development budgets are also rare in funding schemes supporting smaller cultural production endeavours and it is rather common for paracticioners themselves to dabble in experimental development or to have a creative coder on the team.
In order keep the budgetary requirements for such an implementation at a minimum, it is imperative to rely on open standards and non-proprietary components.

While the implementation has to fulfill a very specific task, abstraction, modular composition and separation of concerns are important design factors that would ideally allow to establish an abstract base that can be reused in multiple contexts with less work in subsequent instances of deployment.
To support a broad range of scenarios, the application core should support the real-time streaming of any type of sensor data in addition to the usual video and audio streams.
This would allow augmenting the telepresence environment with spatial data, sensor readings or generative data sources.
The data could then be streamed as is, but visualised, sonified or otherwise analysed and processed on the receiving devices as required by the implement use-case.
In this particular case, movement sonification is implemented as an alternative to the usual visually-centered conferencing paradigms.
As movement in front of a screen or with headsets can be rather limiting, the idea is to provide spatial audio as a medium for verbal communication, transmission of audible representations of movement and a sense of positional orientation in relation to the virtual presence in the space.
Focused on a scenario of two participants moving at remote locations, but in virtually merged spatial dimensions, this setup could enable exploration of moving together by attempting to achieve some form of acoustic harmony or rhythm to supplant the lack of an actual shared pyhsical presence.
This implementation targets only a small audience in that it requires practice and a deep engagement with the sonification method, as it would be specifically built to express a certain style of movment that would not be inituitive for every potential user alike.
It should also be used by dancers that already have a shared experience of moving together so that verbal communication can support navigating a shared movement vocabulary and connects to the memory of shared physical practice.
Creative design processes and user experience are deemed outside the scope of this study, as the focus lies on examining the general feasibility and affordability of using open standards and free software to enable the creation of a task-specifc real-time application.

\section{Method}

The study starts from a survey of \emph{conceptual foundations} to present existing paradigms and technologies supporting the development of web-based real-time applications, establishes a \emph{methodology} and presents an \emph{application concept} as well as the resulting {reference implementation}.
The reference implementation is the basis for an \emph{evaluation} of its general functionality, a \emph{critical reflection} on the development process.
The study concludes with a general recommendation on the feasibility of creating such a \textquoted{single\-use} application for a specific task as well as an outlook for future implications and possibilites resulting from this research.
